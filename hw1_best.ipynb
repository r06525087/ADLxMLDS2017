{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Concatenate,Masking,Add,concatenate, UpSampling1D,MaxPooling1D,Input,Dense,LSTM,TimeDistributed,Activation,Dropout,BatchNormalization,Conv1D,Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.layers import convolutional\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "\n",
    "import sys\n",
    "path_1 = sys.argv[1]\n",
    "path_2 = sys.argv[2]\n",
    "\n",
    "time_step = 36\n",
    "\n",
    "#### 讀取MFCC特徵\n",
    "\n",
    "file = open(path_1+'mfcc/test.ark')\n",
    "\n",
    "test_mfcc=[]\n",
    "for line in file:\n",
    "    test_mfcc.append(line)\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    test_mfcc[i]=test_mfcc[i].split()\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    temp=['s',[]]\n",
    "\n",
    "    for k in range(1,40):\n",
    "        temp[0]=test_mfcc[i][0]\n",
    "        temp[1].append(test_mfcc[i][k])\n",
    "    test_mfcc[i]=temp\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    for k in range (0,39):\n",
    "        test_mfcc[i][1][k]=float(test_mfcc[i][1][k])\n",
    "\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    test_mfcc[i][0]=test_mfcc[i][0].replace('_',' ')\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    test_mfcc[i][0]=test_mfcc[i][0].split()\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    test_mfcc[i][0]=[test_mfcc[i][0][0]+test_mfcc[i][0][1],test_mfcc[i][0][2]]\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    test_mfcc[i][0][1]=int(test_mfcc[i][0][1])\n",
    "\n",
    "process_test_mfcc=[]\n",
    "temp=[]\n",
    "for i in range (0,len(test_mfcc)):\n",
    "    if test_mfcc[i][0][1]==1:\n",
    "        process_test_mfcc.append(temp)\n",
    "        \n",
    "        temp=['name',0]\n",
    "        temp[0]=test_mfcc[i][0][0]\n",
    "        temp.append(test_mfcc[i][1])\n",
    "    else:\n",
    "        temp.append(test_mfcc[i][1]) \n",
    "        \n",
    "        \n",
    "process_test_mfcc.append(temp)\n",
    "process_test_mfcc.remove([])\n",
    "\n",
    "#應該會長得像 [ ['名字',int(向量個數),[vector_1],[vector_2]......[vector_n],.. ] , [...] , [...] ...]\n",
    "\n",
    "process_test_mfcc_2=[]\n",
    "for i in range(0, len(process_test_mfcc)):\n",
    "    temp = [[],[]]\n",
    "    temp[0].append(process_test_mfcc[i][0])\n",
    "    temp[0].append(len(process_test_mfcc[i])-2)\n",
    "    for k in range(2,len(process_test_mfcc[i])):\n",
    "        temp[1].append(process_test_mfcc[i][k])\n",
    "    \n",
    "    process_test_mfcc_2.append(temp)\n",
    "del process_test_mfcc\n",
    "\n",
    "\n",
    "#### 讀取fbank特徵\n",
    "\n",
    "file = open(path_1+'fbank/test.ark')\n",
    "\n",
    "\n",
    "\n",
    "test_fbank=[]\n",
    "for line in file:\n",
    "    test_fbank.append(line)\n",
    "\n",
    "for i in range (0,len(test_fbank)):\n",
    "    test_fbank[i]=test_fbank[i].split()\n",
    "for i in range (0,len(test_fbank)):\n",
    "    temp=['s',[]]\n",
    "\n",
    "    for k in range(1,70):\n",
    "        temp[0]=test_fbank[i][0]\n",
    "        temp[1].append(test_fbank[i][k])\n",
    "    test_fbank[i]=temp\n",
    "for i in range (0,len(test_fbank)):\n",
    "    for k in range (0,69):\n",
    "        test_fbank[i][1][k]=float(test_fbank[i][1][k])\n",
    "\n",
    "for i in range (0,len(test_fbank)):\n",
    "    test_fbank[i][0]=test_fbank[i][0].replace('_',' ')\n",
    "for i in range (0,len(test_fbank)):\n",
    "    test_fbank[i][0]=test_fbank[i][0].split()\n",
    "for i in range (0,len(test_fbank)):\n",
    "    test_fbank[i][0]=[test_fbank[i][0][0]+test_fbank[i][0][1],test_fbank[i][0][2]]\n",
    "for i in range (0,len(test_fbank)):\n",
    "    test_fbank[i][0][1]=int(test_fbank[i][0][1])\n",
    "\n",
    "process_test_fbank=[]\n",
    "temp=[]\n",
    "for i in range (0,len(test_fbank)):\n",
    "    if test_fbank[i][0][1]==1:\n",
    "        process_test_fbank.append(temp)\n",
    "        \n",
    "        temp=['name',0]\n",
    "        temp[0]=test_fbank[i][0][0]\n",
    "        temp.append(test_fbank[i][1])\n",
    "    else:\n",
    "        temp.append(test_fbank[i][1]) \n",
    "        \n",
    "        \n",
    "process_test_fbank.append(temp)\n",
    "process_test_fbank.remove([])\n",
    "\n",
    "#應該會長得像 [ ['名字',int(向量個數),[vector_1],[vector_2]......[vector_n],.. ] , [...] , [...] ...]\n",
    "\n",
    "process_test_fbank_2=[]\n",
    "for i in range(0, len(process_test_fbank)):\n",
    "    temp = [[],[]]\n",
    "    temp[0].append(process_test_fbank[i][0])\n",
    "    temp[0].append(len(process_test_fbank[i])-2)\n",
    "    for k in range(2,len(process_test_fbank[i])):\n",
    "        temp[1].append(process_test_fbank[i][k])\n",
    "    \n",
    "    process_test_fbank_2.append(temp)\n",
    "del process_test_fbank\n",
    "\n",
    "\n",
    "def seperate_test_data(input_data_2,seq_len,fill_thing):\n",
    "    \n",
    "    return_list = []\n",
    "    \n",
    "    \n",
    "    name_list=[]\n",
    "    \n",
    "    for i in range(0,len(input_data_2)):\n",
    "        name_list.append(input_data_2[i][0])\n",
    "    \n",
    "    \n",
    "\n",
    "    data_list = []\n",
    "    \n",
    "    for i in range(0,len(input_data_2)):\n",
    "        \n",
    "        one_sentence = []\n",
    "        phone_num = (int( len(input_data_2[i][1])/seq_len ) +1)*seq_len #計算每個句子補完後該有的長度\n",
    "        \n",
    "        for k in range(0,phone_num-len(input_data_2[i][1])):\n",
    "            input_data_2[i][1].append(fill_thing)  #長度不夠的部分由fill_thing補完\n",
    "        \n",
    "        for j in range(0,int(phone_num/seq_len)):\n",
    "            part_list = []                         #準備整串PHONE/SEQ_LEN數量的LIST\n",
    "            part_list = input_data_2[i][1][seq_len*j:seq_len*(j+1)]\n",
    "        \n",
    "            one_sentence.append(part_list)\n",
    "        \n",
    "        data_list.append(one_sentence)\n",
    "    \n",
    "    return_list.append(name_list)\n",
    "    return_list.append(data_list)\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "process_test_mfcc_2 = seperate_test_data(process_test_mfcc_2,time_step,np.zeros(39))\n",
    "process_test_fbank_2 = seperate_test_data(process_test_fbank_2,time_step,np.zeros(69))\n",
    "\n",
    "def evaluate_all(input_list_1,input_list_2):\n",
    "    return_list = []\n",
    "    \n",
    "    for i in range(0,len(input_list_1[1])):\n",
    "        one_person_data = []\n",
    "        \n",
    "        one_person_data.append(input_list_1[0][i][0]) #小list的第一筆是第i筆資料的人名\n",
    "\n",
    "        i_predict = model.predict(x=([np.array(input_list_1[1][i]),\n",
    "                                      np.array(input_list_2[1][i])])) #將第i筆資料的data取出來預測\n",
    "        i_predict = list(i_predict)\n",
    "        \n",
    "        predict_list = [] #用來裝預測完的東西\n",
    "        \n",
    "        for m in range(0,len(i_predict)):\n",
    "            for n in range(0,len(i_predict[0])):\n",
    "                predict_list.append(list(i_predict[m][n]))\n",
    "            \n",
    "        \n",
    "        phone_number=[]                        #用來裝一串數字\n",
    "        \n",
    "        for k in range(0,input_list_1[0][i][1]): #k是實際有的PHONE數量 所以只做K次\n",
    "            \n",
    "            idx = predict_list[k].index(max(predict_list[k]))\n",
    "            \n",
    "            phone_number.append(idx)\n",
    "            \n",
    "        \n",
    "        one_person_data.append(phone_number)\n",
    "        \n",
    "        return_list.append(one_person_data)\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "result=evaluate_all(process_test_mfcc_2,process_test_fbank_2)\n",
    "\n",
    "\n",
    "for i in range(0,len(result)):\n",
    "    for k in range(0,len(result[i][1])):\n",
    "        if result[i][1][k]==39:\n",
    "\n",
    "            result[i][1][k]=30\n",
    "\n",
    "def delete_sil_continue(input_result):\n",
    "    for i in range(len(input_result)):\n",
    "\n",
    "        data_list=[]\n",
    "        data_list.append(input_result[i][1][0])\n",
    "    \n",
    "        for k in range(0,len(input_result[i][1])):\n",
    "            if input_result[i][1][k]!=data_list[len(data_list)-1]:\n",
    "                data_list.append(input_result[i][1][k])\n",
    "        \n",
    "        if data_list[0]==30:\n",
    "            del(data_list[0])\n",
    "        if data_list[-1]==30:\n",
    "            del(data_list[-1])\n",
    "        \n",
    "        input_result[i][1]=data_list\n",
    "\n",
    "delete_sil_continue(result)\n",
    "\n",
    "num_to_phone={0:'aa',  1:'ae',  2:'ah',  3:'aw',  4:'ay',  5:'b',  6:'ch',  7:'d',  8:'dh',  9:'dx',  \n",
    "              10:'eh',11:'er', 12:'ey',  13:'f',  14:'g',15:'hh', 16:'ih',17:'iy', 18:'jh',  19:'k',  \n",
    "               20:'l', 21:'m',  22:'n', 23:'ng', 24:'ow',25:'oy',  26:'p', 27:'r',  28:'s', 29:'sh',\n",
    "             30:'sil', 31:'t' ,32:'th', 33:'uh', 34:'uw', 35:'v',  36:'w', 37:'y',  38:'z'}\n",
    "\n",
    "final_diction={'aa':'a', 'ae':'b', 'ah':'c', 'aw':'e', 'ay':'g', 'b':'h', 'ch':'i', 'd':'k', 'dh':'l', 'dx':'m',\n",
    "               'eh':'n', 'er':'r', 'ey':'s', 'f':'t',  'g':'u',  'hh':'v','ih':'w', 'iy':'y','jh':'z', 'k':'A',\n",
    "               'l' :'B', 'm':'C',  'n':'D',  'ng':'E', 'ow':'F', 'oy':'G','p':'H',  'r':'I', 's':'J',  'sh':'K',\n",
    "               'sil':'L','t':'M',  'th':'N', 'uh':'O', 'uw':'P', 'v':'Q', 'w':'S',  'y':'T', 'z':'U'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def turn_num_to_phone(input_result):\n",
    "    final_result=[]\n",
    "    \n",
    "    for i in range(0,len(input_result)):\n",
    "        the_result=[]\n",
    "       \n",
    "        name = input_result[i][0]\n",
    "        name = name[0:5]+'_'+name[5:]\n",
    "        \n",
    "        the_result.append(name) #名字\n",
    "\n",
    "       \n",
    "        input_result[i][1]=[num_to_phone[x] if x in num_to_phone else x for x in input_result[i][1]] \n",
    "        input_result[i][1]=[final_diction[x] if x in final_diction else x for x in input_result[i][1]]\n",
    "        \n",
    "        first_phone=input_result[i][1][0]\n",
    "        \n",
    "        for k in range(1,len(input_result[i][1])):\n",
    "            first_phone = first_phone+input_result[i][1][k]\n",
    "        \n",
    "        the_result.append(first_phone)\n",
    "    \n",
    "        final_result.append(the_result)\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "OK_result = turn_num_to_phone(result) \n",
    "\n",
    "import csv\n",
    "\n",
    "with open(path_2+'.csv', mode='w', encoding='utf-8') as write_file:\n",
    "    writer = csv.writer(write_file, delimiter=',')\n",
    "\n",
    "\n",
    "    writer.writerow(['id','phone_sequence'])\n",
    "    for i in range (0,len(OK_result)):\n",
    "        writer.writerow(OK_result[i])\n",
    "        \n",
    "        \n",
    "##################   TRAINING  CODE   ##################\n",
    "\n",
    "# import csv\n",
    "\n",
    "# all_data =[]\n",
    "\n",
    "# with open('train.csv', mode='r', encoding='utf-8') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for row in reader:\n",
    "#         row[0] = row[0].replace('_',' ') #把底線用空白代替\n",
    "#         row[0] = row[0].split()          #讀到空白就分開\n",
    "#         all_data.append(row)\n",
    "#     #    print(row)\n",
    "# all_data[0][0]=['maeb0', 'si1411', '1'] \n",
    "\n",
    "# for i in range (0,len(all_data)):\n",
    "#     all_data[i][0]=[all_data[i][0][0]+all_data[i][0][1],all_data[i][0][2]]\n",
    "\n",
    "# process_data = [ [['maeb0si1411', '1'], 'sil'] ] \n",
    "\n",
    "# k=0\n",
    "\n",
    "# for i in range (1,len(all_data)):\n",
    "#     if all_data[i][0][0] == process_data[k][0][0]:\n",
    "#         process_data[k].append(all_data[i][1])\n",
    "#     else:\n",
    "#         process_data.append(all_data[i])\n",
    "#         k+=1\n",
    "\n",
    "# for i in range (0,len(process_data)):\n",
    "#     process_data[i][0][1]=len(process_data[i])-1\n",
    "\n",
    "# sentence_lenth = []\n",
    "# for i in range (0,len(process_data)):\n",
    "#     sentence_lenth.append(process_data[i][0][1])\n",
    "\n",
    "# #process_data是目前的 [ [ ['名字',音節長度],'phone1','phone2',... ] , [ ] ....] \n",
    "\n",
    "\n",
    "# process_data_2 = []\n",
    "# for i in range (0,len(process_data)):\n",
    "#     temp = [[],[]]\n",
    "#     temp[0]=(process_data[i][0])\n",
    "#     for k in range(1,process_data[i][0][1]+1):\n",
    "#         temp[1].append(process_data[i][k])\n",
    "#     process_data_2.append(temp)\n",
    "# #應該會長得像 [ ['名字', 音節長度 ] , ['phone1','phone2',... ] ]\n",
    "\n",
    "# phone_change = {'ao':'aa', 'ax':'ah',  'cl':'sil','el':'l',\n",
    "#                 'en':'n' , 'epi':'sil','ix':'ih', 'vcl':'sil','zh':'sh'}\n",
    "\n",
    "# for i in range (0,len(process_data_2)):\n",
    "#     process_data_2[i][1] = [phone_change[x] if x in phone_change else x for x in process_data_2[i][1]]\n",
    "    \n",
    "\n",
    "# label_vector={\n",
    "# 'aa':0,\n",
    "# 'ae':1,\n",
    "# 'ah':2,\n",
    "\n",
    "# 'aw':3,\n",
    "\n",
    "# 'ay':4,\n",
    "# 'b':5,\n",
    "# 'ch':6,\n",
    "\n",
    "# 'd':7,\n",
    "# 'dh':8,\n",
    "# 'dx':9,\n",
    "# 'eh':10,\n",
    "\n",
    "# 'er':11,\n",
    "# 'ey':12,\n",
    "# 'f':13,\n",
    "# 'g':14,\n",
    "# 'hh':15,\n",
    "# 'ih':16,\n",
    "\n",
    "# 'iy':17,\n",
    "# 'jh':18,\n",
    "# 'k':19,\n",
    "# 'l':20,\n",
    "# 'm':21,\n",
    "# 'n':22,\n",
    "# 'ng':23,\n",
    "# 'ow':24,\n",
    "# 'oy':25,\n",
    "# 'p':26,\n",
    "# 'r':27,\n",
    "# 's':28,\n",
    "# 'sh':29,\n",
    "# 'sil':30,\n",
    "# 't':31,\n",
    "# 'th':32,\n",
    "# 'uh':33,\n",
    "# 'uw':34,\n",
    "# 'v':35,\n",
    "\n",
    "# 'w':36,\n",
    "# 'y':37,\n",
    "# 'z':38,\n",
    "# }\n",
    "# for i in range(0,len(process_data_2)):\n",
    "    \n",
    "#     process_data_2[i][1] = [label_vector[x] if x in label_vector else x for x in process_data_2[i][1]] \n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# for i in range(0,len(process_data_2)):\n",
    "#     for k in range (0,process_data_2[i][0][1]):\n",
    "#         num = process_data_2[i][1][k]\n",
    "#         process_data_2[i][1][k]=np.zeros(40) #補到40維 多一個是等等用來補0的\n",
    "#         process_data_2[i][1][k][num]=1\n",
    "\n",
    "        \n",
    "# file = open('train_mfcc.txt')\n",
    "\n",
    "# mfcc=[]\n",
    "# for line in file:\n",
    "#     mfcc.append(line)\n",
    "\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     mfcc[i]=mfcc[i].split()\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     temp=['s',[]]\n",
    "\n",
    "#     for k in range(1,40):\n",
    "#         temp[0]=mfcc[i][0]\n",
    "#         temp[1].append(mfcc[i][k])\n",
    "#     mfcc[i]=temp\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     for k in range (0,39):\n",
    "#         mfcc[i][1][k]=float(mfcc[i][1][k])\n",
    "\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     mfcc[i][0]=mfcc[i][0].replace('_',' ')\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     mfcc[i][0]=mfcc[i][0].split()\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     mfcc[i][0]=[mfcc[i][0][0]+mfcc[i][0][1],mfcc[i][0][2]]\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     mfcc[i][0][1]=int(mfcc[i][0][1])\n",
    "\n",
    "# process_mfcc=[]\n",
    "# temp=[]\n",
    "# for i in range (0,len(mfcc)):\n",
    "#     if mfcc[i][0][1]==1:\n",
    "#         process_mfcc.append(temp)\n",
    "        \n",
    "#         temp=['name',0]\n",
    "#         temp[0]=mfcc[i][0][0]\n",
    "#         temp.append(mfcc[i][1])\n",
    "#     else:\n",
    "#         temp.append(mfcc[i][1]) \n",
    "        \n",
    "        \n",
    "# process_mfcc.append(temp)\n",
    "# process_mfcc.remove([])\n",
    "\n",
    "# #應該會長得像 [ ['名字',int(向量個數),[vector_1],[vector_2]......[vector_n],.. ] , [...] , [...] ...]\n",
    "\n",
    "# process_mfcc_2=[]\n",
    "# for i in range(0, len(process_mfcc)):\n",
    "#     temp = [[],[]]\n",
    "#     temp[0].append(process_mfcc[i][0])\n",
    "#     temp[0].append(len(process_mfcc[i])-2)\n",
    "#     for k in range(2,len(process_mfcc[i])):\n",
    "#         temp[1].append(process_mfcc[i][k])\n",
    "    \n",
    "#     process_mfcc_2.append(temp)\n",
    "    \n",
    "# del process_mfcc\n",
    "# #變成 [['名字',向量數],[ 好多個向量list在這   ]]\n",
    "\n",
    "\n",
    "# for i in range (0,len(process_data_2)):\n",
    "#     for k in range(0,len(process_mfcc_2)):\n",
    "#         if process_mfcc_2[k][0][0] == process_data_2[i][0][0]:\n",
    "#             temp = []\n",
    "#             temp = process_mfcc_2[k]\n",
    "#             process_mfcc_2[k] = process_mfcc_2[i]\n",
    "#             process_mfcc_2[i] = temp\n",
    "\n",
    "# file = open('train_fbank.txt')\n",
    "\n",
    "# fbank=[]\n",
    "# for line in file:\n",
    "#     fbank.append(line)\n",
    "\n",
    "# for i in range (0,len(fbank)):\n",
    "#     fbank[i]=fbank[i].split()\n",
    "# for i in range (0,len(fbank)):\n",
    "#     temp=['s',[]]\n",
    "\n",
    "#     for k in range(1,70):\n",
    "#         temp[0]=fbank[i][0]\n",
    "#         temp[1].append(fbank[i][k])\n",
    "#     fbank[i]=temp\n",
    "# for i in range (0,len(fbank)):\n",
    "#     for k in range (0,69):\n",
    "#         fbank[i][1][k]=float(fbank[i][1][k])\n",
    "\n",
    "# for i in range (0,len(fbank)):\n",
    "#     fbank[i][0]=fbank[i][0].replace('_',' ')\n",
    "# for i in range (0,len(fbank)):\n",
    "#     fbank[i][0]=fbank[i][0].split()\n",
    "# for i in range (0,len(fbank)):\n",
    "#     fbank[i][0]=[fbank[i][0][0]+fbank[i][0][1],fbank[i][0][2]]\n",
    "# for i in range (0,len(fbank)):\n",
    "#     fbank[i][0][1]=int(fbank[i][0][1])\n",
    "\n",
    "# process_fbank=[]\n",
    "# temp=[]\n",
    "# for i in range (0,len(fbank)):\n",
    "#     if fbank[i][0][1]==1:\n",
    "#         process_fbank.append(temp)\n",
    "        \n",
    "#         temp=['name',0]\n",
    "#         temp[0]=fbank[i][0][0]\n",
    "#         temp.append(fbank[i][1])\n",
    "#     else:\n",
    "#         temp.append(fbank[i][1]) \n",
    "        \n",
    "        \n",
    "# process_fbank.append(temp)\n",
    "# process_fbank.remove([])\n",
    "\n",
    "# #應該會長得像 [ ['名字',int(向量個數),[vector_1],[vector_2]......[vector_n],.. ] , [...] , [...] ...]\n",
    "\n",
    "# process_fbank_2=[]\n",
    "# for i in range(0, len(process_fbank)):\n",
    "#     temp = [[],[]]\n",
    "#     temp[0].append(process_fbank[i][0])\n",
    "#     temp[0].append(len(process_fbank[i])-2)\n",
    "#     for k in range(2,len(process_fbank[i])):\n",
    "#         temp[1].append(process_fbank[i][k])\n",
    "    \n",
    "#     process_fbank_2.append(temp)\n",
    "# del process_fbank\n",
    "# #變成 [['名字',向量數],[ 好多個向量list在這   ]]\n",
    "\n",
    "# for i in range (0,len(process_fbank_2)):\n",
    "#     for k in range(0,len(process_fbank_2)):\n",
    "#         if process_fbank_2[k][0][0] == process_data_2[i][0][0]:\n",
    "#             temp = []\n",
    "#             temp = process_fbank_2[k]\n",
    "#             process_fbank_2[k] = process_fbank_2[i]\n",
    "#             process_fbank_2[i] = temp\n",
    "#             count +=1\n",
    "# def seperate_data(input_list,num,fill_thing):\n",
    "\n",
    "#     seperated_data = []\n",
    "#     data_part = []  # [ ] = 裡面是每一筆都是不同句的 data list\n",
    "\n",
    "#     for i in range(0,len(input_list)):              #進來的第i筆資料先取出第1項\n",
    "#         data_part.append(input_list[i][1])\n",
    "    \n",
    "#     for i in range (0,len(data_part)):              #對於DATA PART的第i筆資料\n",
    "#         prepare_num = int(len(data_part[i])/num)+1  #prepare_num = 替每一筆資料要準備的LIST數\n",
    "        \n",
    "#         for k in range(0,prepare_num*num-len(data_part[i])): #先幫每筆資料補滿0\n",
    "#             data_part[i].append(fill_thing)                  #從0到 ~ (LIST數*num-原本長度) 為要補東西的數量\n",
    "        \n",
    "#         for j in range(0,prepare_num):              #製作 prepare_num數量的LIST\n",
    "#             ok_data=[]\n",
    "            \n",
    "#             ok_data = data_part[i][num*j:num*(j+1)]\n",
    "            \n",
    "#             seperated_data.append(ok_data)\n",
    "    \n",
    "#     return seperated_data\n",
    "\n",
    "# ###\n",
    "# time_step = 36\n",
    "\n",
    "# ###製作空缺的標籤\n",
    "\n",
    "# no_voice_label = np.zeros(40)\n",
    "# no_voice_label[39]=1\n",
    "# no_voice_label = np.array(no_voice_label)\n",
    "# print(no_voice_label)\n",
    "\n",
    "# ###\n",
    "\n",
    "# input_x_1 = seperate_data(process_mfcc_2,time_step,np.zeros(39))  \n",
    "# input_x_2 = seperate_data(process_fbank_2,time_step,np.zeros(69))\n",
    "# input_y = seperate_data(process_data_2,time_step,no_voice_label)\n",
    "# ###\n",
    "\n",
    "# input_x_1=np.array(input_x_1)\n",
    "# input_x_2=np.array(input_x_2)\n",
    "# input_y=np.array(input_y)\n",
    "\n",
    "# print(input_x_1.shape,input_x_2.shape,input_y.shape)\n",
    "\n",
    "\n",
    "# ####\n",
    "# input_mfcc = Input(shape=(time_step,39))\n",
    "# mfcc_BN = BatchNormalization()(input_mfcc)\n",
    "# mfcc_conv = Conv1D(filters=128,\n",
    "#                    kernel_size=7,\n",
    "#                    padding='causal',\n",
    "#                    strides=1)(mfcc_BN)\n",
    "# mfcc_activation_1 = LeakyReLU()(mfcc_conv)\n",
    "# mfcc_drop = Dropout(0.25)(mfcc_activation_1)\n",
    "\n",
    "\n",
    "# ####\n",
    "# input_fbank = Input(shape=(time_step,69))\n",
    "# fbank_BN = BatchNormalization()(input_fbank)\n",
    "# fbank_conv = Conv1D(filters=128,\n",
    "#                    kernel_size=7,\n",
    "#                    padding='causal',\n",
    "#                    strides=1)(fbank_BN)\n",
    "\n",
    "# fbank_activation_1 = LeakyReLU()(fbank_conv)\n",
    "# fbank_drop = Dropout(0.25)(fbank_activation_1)\n",
    "\n",
    "# ####\n",
    "\n",
    "# merge = Add()([mfcc_drop,fbank_drop])\n",
    "\n",
    "# All_layer = BatchNormalization()(merge)\n",
    "\n",
    "# All_LSTM_1 = Bidirectional(LSTM(units=128,return_sequences=True))(All_layer)\n",
    "# Activation_1 = LeakyReLU()(All_LSTM_1)\n",
    "# All_Drop_1 = Dropout(0.25)(Activation_1)\n",
    "\n",
    "# All_LSTM_2 = Bidirectional(LSTM(units=256,return_sequences=True))(All_Drop_1)\n",
    "# Activation_2 = LeakyReLU()(All_LSTM_2)\n",
    "# All_Drop_2 = Dropout(0.25)(Activation_2)\n",
    "\n",
    "\n",
    "# All_LSTM_4 = Bidirectional(LSTM(units=256,return_sequences=True))(All_Drop_2)\n",
    "# Activation_4 = LeakyReLU()(All_LSTM_4)\n",
    "# All_Drop_4 = Dropout(0.25)(Activation_4)\n",
    "\n",
    "\n",
    "\n",
    "# Time = TimeDistributed(Dense(units=40))(All_Drop_4)\n",
    "\n",
    "\n",
    "# result_layer = Activation('softmax')(Time)\n",
    "\n",
    "\n",
    "# model = Model(inputs=[input_mfcc, input_fbank], outputs=result_layer)\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.fit( x=([input_x_1,input_x_2]),\n",
    "#            y= input_y ,\n",
    "#            batch_size=150,\n",
    "#            epochs=6,\n",
    "#            validation_split=0)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
